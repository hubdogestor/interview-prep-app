{
  "version": 3,
  "sources": [],
  "debugId": "0ba6b81e-de92-2da1-6f27-d8fcdd54bba6",
  "sections": [
    {"offset": {"line": 35, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/server/trpc.ts"],"sourcesContent":["import { initTRPC } from '@trpc/server';\r\nimport SuperJSON from 'superjson';\r\nimport { ZodError } from 'zod';\r\nimport type { Context } from './context';\r\n\r\nconst t = initTRPC.context<Context>().create({\r\n  transformer: SuperJSON,\r\n  errorFormatter({ shape, error }) {\r\n    return {\r\n      ...shape,\r\n      data: {\r\n        ...shape.data,\r\n        zodError:\r\n          error.cause instanceof ZodError ? error.cause.flatten() : null,\r\n      },\r\n    };\r\n  },\r\n});\r\n\r\nexport const router = t.router;\r\nexport const publicProcedure = t.procedure;"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AAGA,MAAM,IAAI,+KAAQ,CAAC,OAAO,GAAY,MAAM,CAAC;IAC3C,aAAa,uJAAS;IACtB,gBAAe,EAAE,KAAK,EAAE,KAAK,EAAE;QAC7B,OAAO;YACL,GAAG,KAAK;YACR,MAAM;gBACJ,GAAG,MAAM,IAAI;gBACb,UACE,MAAM,KAAK,YAAY,4JAAQ,GAAG,MAAM,KAAK,CAAC,OAAO,KAAK;YAC9D;QACF;IACF;AACF;AAEO,MAAM,SAAS,EAAE,MAAM;AACvB,MAAM,kBAAkB,EAAE,SAAS","debugId":null}},
    {"offset": {"line": 65, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/lib/ai/provider.ts"],"sourcesContent":["// lib/ai/provider.ts\r\nimport Anthropic from '@anthropic-ai/sdk';\r\nimport { GoogleGenerativeAI } from '@google/generative-ai';\r\nimport OpenAI from 'openai';\r\n\r\nexport type AIProvider = 'gemini' | 'openai' | 'claude';\r\n\r\n// Ordem de prioridade: Gemini > OpenAI > Claude\r\nconst PROVIDER_PRIORITY: AIProvider[] = ['gemini', 'openai', 'claude'];\r\n\r\n// Clientes das APIs\r\nconst claudeClient = new Anthropic({\r\n  apiKey: process.env.ANTHROPIC_API_KEY,\r\n});\r\n\r\nconst geminiClient = new GoogleGenerativeAI(\r\n  process.env.GOOGLE_AI_API_KEY || ''\r\n);\r\n\r\nconst openaiClient = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\ninterface AIRequest {\r\n  prompt: string;\r\n  systemPrompt?: string;\r\n  maxTokens?: number;\r\n  temperature?: number;\r\n}\r\n\r\ninterface AIResponse {\r\n  text: string;\r\n  provider: AIProvider;\r\n  usage?: {\r\n    promptTokens: number;\r\n    completionTokens: number;\r\n  };\r\n}\r\n\r\n/**\r\n * Sistema h√≠brido com fallback autom√°tico\r\n * 1. Gemini 2.5 Flash-Lite (Prim√°rio - Gratuito, super r√°pido, sem thinking mode)\r\n * 2. OpenAI GPT-4o-mini (Secund√°rio - Melhor custo-benef√≠cio)\r\n * 3. Claude 3.5 Sonnet (Terci√°rio - Alta qualidade, requer cr√©ditos)\r\n *\r\n * Nota: Flash-Lite √© otimizado para velocidade/custo, sem thinking mode.\r\n * Flash e Pro usam thinking que consome tokens sem gerar resposta vis√≠vel.\r\n */\r\nexport async function generateWithFallback(\r\n  request: AIRequest\r\n): Promise<AIResponse> {\r\n  const errors: Record<AIProvider, Error | null> = {\r\n    claude: null,\r\n    gemini: null,\r\n    openai: null,\r\n  };\r\n\r\n  // Tenta cada provider na ordem de prioridade\r\n  for (const provider of PROVIDER_PRIORITY) {\r\n    try {\r\n      console.log(`ü§ñ Tentando provider: ${provider}`);\r\n      const response = await generateWithProvider(provider, request);\r\n      console.log(`‚úÖ Sucesso com ${provider}`);\r\n      return response;\r\n    } catch (error) {\r\n      errors[provider] = error as Error;\r\n      console.log(`‚ùå Falha com ${provider}:`, error);\r\n      // Continua para o pr√≥ximo provider\r\n    }\r\n  }\r\n\r\n  // Se todos falharem, lan√ßa erro com detalhes\r\n  throw new Error(\r\n    `Todos os providers de IA falharam:\\n${Object.entries(errors)\r\n      .map(([provider, error]) => `${provider}: ${error?.message}`)\r\n      .join('\\n')}`\r\n  );\r\n}\r\n\r\n/**\r\n * Combina system prompt com user prompt\r\n */\r\nfunction buildPrompt(prompt: string, systemPrompt?: string): string {\r\n  return systemPrompt ? `${systemPrompt}\\n\\n${prompt}` : prompt;\r\n}\r\n\r\n/**\r\n * Valida resposta do provider\r\n */\r\nfunction validateResponse(text: string | null | undefined, provider: string): string {\r\n  if (!text) {\r\n    throw new Error(`${provider} retornou resposta vazia`);\r\n  }\r\n  return text;\r\n}\r\n\r\n/**\r\n * Gera resposta usando Gemini 2.5 Flash-Lite\r\n */\r\nasync function generateWithGemini(request: AIRequest): Promise<AIResponse> {\r\n  const { prompt, systemPrompt, maxTokens = 1000, temperature = 0.7 } = request;\r\n\r\n  const model = geminiClient.getGenerativeModel({\r\n    model: 'gemini-2.5-flash-lite',\r\n  });\r\n\r\n  const result = await model.generateContent({\r\n    contents: [{ role: 'user', parts: [{ text: buildPrompt(prompt, systemPrompt) }] }],\r\n    generationConfig: { maxOutputTokens: maxTokens, temperature },\r\n  });\r\n\r\n  return {\r\n    text: validateResponse(result.response.text(), 'Gemini'),\r\n    provider: 'gemini',\r\n  };\r\n}\r\n\r\n/**\r\n * Gera resposta usando OpenAI GPT-4o-mini\r\n */\r\nasync function generateWithOpenAI(request: AIRequest): Promise<AIResponse> {\r\n  const { prompt, systemPrompt, maxTokens = 1000, temperature = 0.7 } = request;\r\n\r\n  const messages = [\r\n    ...(systemPrompt ? [{ role: 'system' as const, content: systemPrompt }] : []),\r\n    { role: 'user' as const, content: prompt },\r\n  ];\r\n\r\n  const response = await openaiClient.chat.completions.create({\r\n    model: 'gpt-4o-mini',\r\n    max_tokens: maxTokens,\r\n    temperature,\r\n    messages,\r\n  });\r\n\r\n  return {\r\n    text: validateResponse(response.choices[0]?.message?.content, 'OpenAI'),\r\n    provider: 'openai',\r\n    usage: {\r\n      promptTokens: response.usage?.prompt_tokens || 0,\r\n      completionTokens: response.usage?.completion_tokens || 0,\r\n    },\r\n  };\r\n}\r\n\r\n/**\r\n * Gera resposta usando Claude 3.5 Sonnet\r\n */\r\nasync function generateWithClaude(request: AIRequest): Promise<AIResponse> {\r\n  const { prompt, systemPrompt, maxTokens = 1000, temperature = 0.7 } = request;\r\n\r\n  const response = await claudeClient.messages.create({\r\n    model: 'claude-3-5-sonnet-20241022',\r\n    max_tokens: maxTokens,\r\n    temperature,\r\n    system: systemPrompt,\r\n    messages: [{ role: 'user', content: prompt }],\r\n  });\r\n\r\n  const text = response.content[0].type === 'text' ? response.content[0].text : '';\r\n\r\n  return {\r\n    text: validateResponse(text, 'Claude'),\r\n    provider: 'claude',\r\n    usage: {\r\n      promptTokens: response.usage.input_tokens,\r\n      completionTokens: response.usage.output_tokens,\r\n    },\r\n  };\r\n}\r\n\r\n/**\r\n * Gera resposta usando um provider espec√≠fico\r\n */\r\nasync function generateWithProvider(\r\n  provider: AIProvider,\r\n  request: AIRequest\r\n): Promise<AIResponse> {\r\n  switch (provider) {\r\n    case 'gemini':\r\n      return generateWithGemini(request);\r\n    case 'openai':\r\n      return generateWithOpenAI(request);\r\n    case 'claude':\r\n      return generateWithClaude(request);\r\n    default:\r\n      throw new Error(`Provider n√£o suportado: ${provider}`);\r\n  }\r\n}\r\n\r\n/**\r\n * For√ßa uso de um provider espec√≠fico (√∫til para testes)\r\n */\r\nexport async function generateWithSpecificProvider(\r\n  provider: AIProvider,\r\n  request: AIRequest\r\n): Promise<AIResponse> {\r\n  return generateWithProvider(provider, request);\r\n}"],"names":[],"mappings":"AAAA,qBAAqB;;;;;;;AACrB;AAAA;AACA;AACA;AAAA;;;;AAIA,gDAAgD;AAChD,MAAM,oBAAkC;IAAC;IAAU;IAAU;CAAS;AAEtE,oBAAoB;AACpB,MAAM,eAAe,IAAI,wMAAS,CAAC;IACjC,QAAQ,QAAQ,GAAG,CAAC,iBAAiB;AACvC;AAEA,MAAM,eAAe,IAAI,sLAAkB,CACzC,QAAQ,GAAG,CAAC,iBAAiB,IAAI;AAGnC,MAAM,eAAe,IAAI,mLAAM,CAAC;IAC9B,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;AA2BO,eAAe,qBACpB,OAAkB;IAElB,MAAM,SAA2C;QAC/C,QAAQ;QACR,QAAQ;QACR,QAAQ;IACV;IAEA,6CAA6C;IAC7C,KAAK,MAAM,YAAY,kBAAmB;QACxC,IAAI;YACF,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,UAAU;YAC/C,MAAM,WAAW,MAAM,qBAAqB,UAAU;YACtD,QAAQ,GAAG,CAAC,CAAC,cAAc,EAAE,UAAU;YACvC,OAAO;QACT,EAAE,OAAO,OAAO;YACd,MAAM,CAAC,SAAS,GAAG;YACnB,QAAQ,GAAG,CAAC,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC,EAAE;QACxC,mCAAmC;QACrC;IACF;IAEA,6CAA6C;IAC7C,MAAM,IAAI,MACR,CAAC,oCAAoC,EAAE,OAAO,OAAO,CAAC,QACnD,GAAG,CAAC,CAAC,CAAC,UAAU,MAAM,GAAK,GAAG,SAAS,EAAE,EAAE,OAAO,SAAS,EAC3D,IAAI,CAAC,OAAO;AAEnB;AAEA;;CAEC,GACD,SAAS,YAAY,MAAc,EAAE,YAAqB;IACxD,OAAO,eAAe,GAAG,aAAa,IAAI,EAAE,QAAQ,GAAG;AACzD;AAEA;;CAEC,GACD,SAAS,iBAAiB,IAA+B,EAAE,QAAgB;IACzE,IAAI,CAAC,MAAM;QACT,MAAM,IAAI,MAAM,GAAG,SAAS,wBAAwB,CAAC;IACvD;IACA,OAAO;AACT;AAEA;;CAEC,GACD,eAAe,mBAAmB,OAAkB;IAClD,MAAM,EAAE,MAAM,EAAE,YAAY,EAAE,YAAY,IAAI,EAAE,cAAc,GAAG,EAAE,GAAG;IAEtE,MAAM,QAAQ,aAAa,kBAAkB,CAAC;QAC5C,OAAO;IACT;IAEA,MAAM,SAAS,MAAM,MAAM,eAAe,CAAC;QACzC,UAAU;YAAC;gBAAE,MAAM;gBAAQ,OAAO;oBAAC;wBAAE,MAAM,YAAY,QAAQ;oBAAc;iBAAE;YAAC;SAAE;QAClF,kBAAkB;YAAE,iBAAiB;YAAW;QAAY;IAC9D;IAEA,OAAO;QACL,MAAM,iBAAiB,OAAO,QAAQ,CAAC,IAAI,IAAI;QAC/C,UAAU;IACZ;AACF;AAEA;;CAEC,GACD,eAAe,mBAAmB,OAAkB;IAClD,MAAM,EAAE,MAAM,EAAE,YAAY,EAAE,YAAY,IAAI,EAAE,cAAc,GAAG,EAAE,GAAG;IAEtE,MAAM,WAAW;WACX,eAAe;YAAC;gBAAE,MAAM;gBAAmB,SAAS;YAAa;SAAE,GAAG,EAAE;QAC5E;YAAE,MAAM;YAAiB,SAAS;QAAO;KAC1C;IAED,MAAM,WAAW,MAAM,aAAa,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;QAC1D,OAAO;QACP,YAAY;QACZ;QACA;IACF;IAEA,OAAO;QACL,MAAM,iBAAiB,SAAS,OAAO,CAAC,EAAE,EAAE,SAAS,SAAS;QAC9D,UAAU;QACV,OAAO;YACL,cAAc,SAAS,KAAK,EAAE,iBAAiB;YAC/C,kBAAkB,SAAS,KAAK,EAAE,qBAAqB;QACzD;IACF;AACF;AAEA;;CAEC,GACD,eAAe,mBAAmB,OAAkB;IAClD,MAAM,EAAE,MAAM,EAAE,YAAY,EAAE,YAAY,IAAI,EAAE,cAAc,GAAG,EAAE,GAAG;IAEtE,MAAM,WAAW,MAAM,aAAa,QAAQ,CAAC,MAAM,CAAC;QAClD,OAAO;QACP,YAAY;QACZ;QACA,QAAQ;QACR,UAAU;YAAC;gBAAE,MAAM;gBAAQ,SAAS;YAAO;SAAE;IAC/C;IAEA,MAAM,OAAO,SAAS,OAAO,CAAC,EAAE,CAAC,IAAI,KAAK,SAAS,SAAS,OAAO,CAAC,EAAE,CAAC,IAAI,GAAG;IAE9E,OAAO;QACL,MAAM,iBAAiB,MAAM;QAC7B,UAAU;QACV,OAAO;YACL,cAAc,SAAS,KAAK,CAAC,YAAY;YACzC,kBAAkB,SAAS,KAAK,CAAC,aAAa;QAChD;IACF;AACF;AAEA;;CAEC,GACD,eAAe,qBACb,QAAoB,EACpB,OAAkB;IAElB,OAAQ;QACN,KAAK;YACH,OAAO,mBAAmB;QAC5B,KAAK;YACH,OAAO,mBAAmB;QAC5B,KAAK;YACH,OAAO,mBAAmB;QAC5B;YACE,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,UAAU;IACzD;AACF;AAKO,eAAe,6BACpB,QAAoB,EACpB,OAAkB;IAElB,OAAO,qBAAqB,UAAU;AACxC","debugId":null}},
    {"offset": {"line": 235, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/server/routers/ai.ts"],"sourcesContent":["import { z } from 'zod';\r\nimport { publicProcedure, router } from '../trpc';\r\nimport { generateWithFallback } from '@/lib/ai/provider';\r\n\r\nexport const aiRouter = router({\r\n  generateText: publicProcedure\r\n    .input(\r\n      z.object({\r\n        prompt: z.string().min(1, 'Prompt n√£o pode ser vazio'),\r\n        systemPrompt: z.string().optional(),\r\n        maxTokens: z.number().min(1).max(4000).default(1000),\r\n        temperature: z.number().min(0).max(2).default(0.7),\r\n      })\r\n    )\r\n    .mutation(async ({ input }) => {\r\n      console.log('üîµ [AI Router] Recebeu input:', input);\r\n      \r\n      try {\r\n        const response = await generateWithFallback({\r\n          prompt: input.prompt,\r\n          systemPrompt: input.systemPrompt,\r\n          maxTokens: input.maxTokens,\r\n          temperature: input.temperature,\r\n        });\r\n\r\n        console.log('‚úÖ [AI Router] Resposta gerada com sucesso:', {\r\n          provider: response.provider,\r\n          textLength: response.text.length,\r\n        });\r\n\r\n        return {\r\n          success: true,\r\n          data: response,\r\n        };\r\n      } catch (error) {\r\n        console.error('‚ùå [AI Router] Erro ao gerar texto:', error);\r\n        throw new Error('Falha ao gerar texto. Tente novamente.');\r\n      }\r\n    }),\r\n\r\n  testProviders: publicProcedure.query(async () => {\r\n    const results = {\r\n      claude: false,\r\n      gemini: false,\r\n      openai: false,\r\n    };\r\n\r\n    try {\r\n      await generateWithFallback({ \r\n        prompt: 'Responda apenas: OK',\r\n        maxTokens: 10 \r\n      });\r\n      results.claude = true;\r\n    } catch {\r\n      // Se falhou, tenta os outros\r\n    }\r\n\r\n    return results;\r\n  }),\r\n});"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAEO,MAAM,WAAW,IAAA,iIAAM,EAAC;IAC7B,cAAc,0IAAe,CAC1B,KAAK,CACJ,oLAAC,CAAC,MAAM,CAAC;QACP,QAAQ,oLAAC,CAAC,MAAM,GAAG,GAAG,CAAC,GAAG;QAC1B,cAAc,oLAAC,CAAC,MAAM,GAAG,QAAQ;QACjC,WAAW,oLAAC,CAAC,MAAM,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,MAAM,OAAO,CAAC;QAC/C,aAAa,oLAAC,CAAC,MAAM,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,OAAO,CAAC;IAChD,IAED,QAAQ,CAAC,OAAO,EAAE,KAAK,EAAE;QACxB,QAAQ,GAAG,CAAC,iCAAiC;QAE7C,IAAI;YACF,MAAM,WAAW,MAAM,IAAA,sJAAoB,EAAC;gBAC1C,QAAQ,MAAM,MAAM;gBACpB,cAAc,MAAM,YAAY;gBAChC,WAAW,MAAM,SAAS;gBAC1B,aAAa,MAAM,WAAW;YAChC;YAEA,QAAQ,GAAG,CAAC,8CAA8C;gBACxD,UAAU,SAAS,QAAQ;gBAC3B,YAAY,SAAS,IAAI,CAAC,MAAM;YAClC;YAEA,OAAO;gBACL,SAAS;gBACT,MAAM;YACR;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,sCAAsC;YACpD,MAAM,IAAI,MAAM;QAClB;IACF;IAEF,eAAe,0IAAe,CAAC,KAAK,CAAC;QACnC,MAAM,UAAU;YACd,QAAQ;YACR,QAAQ;YACR,QAAQ;QACV;QAEA,IAAI;YACF,MAAM,IAAA,sJAAoB,EAAC;gBACzB,QAAQ;gBACR,WAAW;YACb;YACA,QAAQ,MAAM,GAAG;QACnB,EAAE,OAAM;QACN,6BAA6B;QAC/B;QAEA,OAAO;IACT;AACF","debugId":null}},
    {"offset": {"line": 295, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/server/routers/_app.ts"],"sourcesContent":["// src/server/routers/_app.ts\r\nimport { router } from '../trpc';\r\nimport { aiRouter } from './ai';\r\n\r\n/**\r\n * Main router - aqui voc√™ adiciona todos os sub-routers\r\n */\r\nexport const appRouter = router({\r\n  ai: aiRouter,\r\n  // Futuramente: profile, icebreakers, competencias, etc.\r\n});\r\n\r\nexport type AppRouter = typeof appRouter;"],"names":[],"mappings":"AAAA,6BAA6B;;;;;AAC7B;AACA;;;AAKO,MAAM,YAAY,IAAA,iIAAM,EAAC;IAC9B,IAAI,4IAAQ;AAEd","debugId":null}},
    {"offset": {"line": 317, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/lib/prisma.ts"],"sourcesContent":["// src/lib/prisma.ts\r\nimport { PrismaClient } from '@prisma/client';\r\n\r\nconst globalForPrisma = globalThis as unknown as {\r\n  prisma: PrismaClient | undefined;\r\n};\r\n\r\nexport const prisma =\r\n  globalForPrisma.prisma ??\r\n  new PrismaClient({\r\n    log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],\r\n  });\r\n\r\nif (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma;"],"names":[],"mappings":"AAAA,oBAAoB;;;;;AACpB;;AAEA,MAAM,kBAAkB;AAIjB,MAAM,SACX,gBAAgB,MAAM,IACtB,IAAI,6IAAY,CAAC;IACf,KAAK,uCAAyC;QAAC;QAAS;QAAS;KAAO,GAAG;AAC7E;AAEF,wCAA2C,gBAAgB,MAAM,GAAG","debugId":null}},
    {"offset": {"line": 337, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/server/context.ts"],"sourcesContent":["// src/server/context.ts\r\nimport { prisma } from '@/lib/prisma';\r\n\r\n/**\r\n * Creates context for an incoming request\r\n * @link https://trpc.io/docs/context\r\n */\r\nexport async function createContext() {\r\n  return {\r\n    prisma,\r\n  };\r\n}\r\n\r\nexport type Context = Awaited<ReturnType<typeof createContext>>;"],"names":[],"mappings":"AAAA,wBAAwB;;;;;AACxB;;AAMO,eAAe;IACpB,OAAO;QACL,QAAA,gIAAM;IACR;AACF","debugId":null}},
    {"offset": {"line": 353, "column": 0}, "map": {"version":3,"sources":["file:///D:/github2/interview-prep-app/src/app/api/trpc/%5Btrpc%5D/route.ts"],"sourcesContent":["import { appRouter } from '@/server/routers/_app';\nimport { createContext } from '@/server/context';\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\n\nexport const runtime = 'nodejs';\n\nasync function handler(req: Request) {\n  return fetchRequestHandler({\n    endpoint: '/api/trpc',\n    req,\n    router: appRouter,\n    createContext,\n    onError:\n      process.env.NODE_ENV === 'development'\n        ? ({ path, error }) => {\n            console.error(\n              `‚ùå [tRPC] Erro no path '${path}':`,\n              error.message\n            );\n          }\n        : undefined,\n  });\n}\n\nexport { handler as GET, handler as POST };"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAEO,MAAM,UAAU;AAEvB,eAAe,QAAQ,GAAY;IACjC,OAAO,IAAA,gMAAmB,EAAC;QACzB,UAAU;QACV;QACA,QAAQ,+IAAS;QACjB,eAAA,2IAAa;QACb,SACE,uCACI,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE;YACd,QAAQ,KAAK,CACX,CAAC,uBAAuB,EAAE,KAAK,EAAE,CAAC,EAClC,MAAM,OAAO;QAEjB,IACA;IACR;AACF","debugId":null}}]
}